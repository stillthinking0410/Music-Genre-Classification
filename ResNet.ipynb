{"cells":[{"cell_type":"code","source":["import os\n","import librosa\n","import librosa.display\n","import matplotlib.pyplot as plt\n","\n","# Define the directory containing the WAV files\n","audio_dir = '/content/drive/MyDrive/Testing'\n","\n","# Define the directory to save the spectrogram images\n","spectrogram_dir = '/content/drive/MyDrive'\n","\n","# Create the spectrogram directory if it doesn't exist\n","os.makedirs(spectrogram_dir, exist_ok=True)\n","\n","# Loop over each WAV file in the audio directory\n","for file in os.listdir(audio_dir):\n","    if file.endswith('.wav'):\n","        try:\n","            # Load the audio file\n","            audio_path = os.path.join(audio_dir, file)\n","            audio, sr = librosa.load(audio_path)\n","\n","            # Generate the spectrogram\n","            spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n","            spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)\n","\n","            # Plot and save the spectrogram image\n","            plt.figure(figsize=(10, 4))\n","            librosa.display.specshow(spectrogram_db, sr=sr, x_axis='time', y_axis='mel')\n","            plt.colorbar(format='%+2.0f dB')\n","            plt.title('Spectrogram - {}'.format(file))\n","            plt.tight_layout()\n","            plt.savefig(os.path.join(spectrogram_dir, '{}.png'.format(os.path.splitext(file)[0])))\n","            plt.close()\n","\n","        except (librosa.LibrosaError, FileNotFoundError) as e:\n","            print(f\"Error processing file '{file}': {str(e)}\")\n"],"metadata":{"id":"G4v22gP5keqD"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"id":"WZElZFnV90Vf","executionInfo":{"status":"ok","timestamp":1689601115310,"user_tz":-330,"elapsed":922464,"user":{"displayName":"Jawahar Reddy","userId":"14346035854948102594"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1fc6edb5-0b4d-44d3-d3c0-6ad20e04abc9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Loss: 1.9401, Accuracy: 31.88%\n","Epoch [2/10], Loss: 1.3877, Accuracy: 57.76%\n","Epoch [3/10], Loss: 0.9924, Accuracy: 74.32%\n","Epoch [4/10], Loss: 0.5324, Accuracy: 89.54%\n","Epoch [5/10], Loss: 0.3278, Accuracy: 94.79%\n","Epoch [6/10], Loss: 0.1701, Accuracy: 98.50%\n","Epoch [7/10], Loss: 0.1045, Accuracy: 99.55%\n","Epoch [8/10], Loss: 0.0696, Accuracy: 99.90%\n","Epoch [9/10], Loss: 0.0468, Accuracy: 100.00%\n","Epoch [10/10], Loss: 0.0384, Accuracy: 99.95%\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.transforms import transforms\n","from PIL import Image\n","import os\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Define the directory containing the spectrogram images\n","spectrogram_dir = '/content/drive/MyDrive/Deep Learning/Augumented Spectogram'\n","\n","# Define the list of target musical genres\n","genres = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n","\n","# Define the transformation to apply to the images\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","# Custom dataset class for loading the spectrogram images\n","class SpectrogramDataset(Dataset):\n","    def __init__(self, spectrogram_dir, genres, transform=None):\n","        self.spectrogram_dir = spectrogram_dir\n","        self.genres = genres\n","        self.transform = transform\n","        self.image_files = []\n","        self.labels = []\n","\n","        # Initialize label encoder\n","        self.label_encoder = LabelEncoder()\n","        self.label_encoder.fit(genres)\n","\n","        # Iterate over each genre folder\n","        for genre in genres:\n","            genre_dir = os.path.join(spectrogram_dir, genre)\n","            if os.path.isdir(genre_dir):\n","                files = os.listdir(genre_dir)\n","                self.image_files.extend(files)\n","                self.labels.extend([genre] * len(files))\n","\n","    def __len__(self):\n","        return len(self.image_files)\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.spectrogram_dir, self.labels[idx], self.image_files[idx])\n","        image = Image.open(img_path).convert('RGB')\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        label = self.labels[idx]\n","        label = self.label_encoder.transform([label])[0]\n","\n","        return image, label\n","\n","# Create the dataset and dataloader\n","dataset = SpectrogramDataset(spectrogram_dir, genres, transform=transform)\n","dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n","\n","# Define the ResNet model\n","class ResNet(nn.Module):\n","    def __init__(self, num_classes):\n","        super(ResNet, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        self.layer1 = self._make_layer(64, 64, 2)\n","        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n","        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n","        self.layer4 = self._make_layer(256, 512, 2, stride=2)\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(512, num_classes)\n","\n","    def _make_layer(self, in_channels, out_channels, blocks, stride=1):\n","        layers = []\n","        layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False))\n","        layers.append(nn.BatchNorm2d(out_channels))\n","        layers.append(nn.ReLU(inplace=True))\n","\n","        for _ in range(1, blocks):\n","            layers.append(nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False))\n","            layers.append(nn.BatchNorm2d(out_channels))\n","            layers.append(nn.ReLU(inplace=True))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc(x)\n","\n","        return x\n","\n","# Modify the last fully connected layer for the number of classes\n","num_classes = len(genres)\n","\n","# Create the ResNet model\n","model = ResNet(num_classes)\n","\n","# Define the loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","# Train the model\n","num_epochs = 10\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    correct_predictions = 0\n","    total_predictions = 0\n","\n","    for images, labels in dataloader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Track the loss\n","        running_loss += loss.item() * images.size(0)\n","\n","        # Track the accuracy\n","        _, predicted_labels = torch.max(outputs.data, 1)\n","        total_predictions += labels.size(0)\n","        correct_predictions += (predicted_labels == labels).sum().item()\n","\n","    epoch_loss = running_loss / len(dataset)\n","    epoch_accuracy = (correct_predictions / total_predictions) * 100\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n","\n","# Save the trained model\n","torch.save(model.state_dict(), '/content/drive/MyDrive/Deep Learning/resnetmodel.pth')\n"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torchvision.transforms import transforms\n","from PIL import Image\n","\n","# Define the number of classes and genre names\n","num_classes = 10\n","genre_names = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n","\n","# Load the pre-trained model\n","model = ResNet(num_classes)\n","model.load_state_dict(torch.load('/content/drive/MyDrive/Deep Learning/resnetmodel.pth'))\n","model.eval()\n","\n","# Define the preprocessing transformations\n","preprocess = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","# Load and preprocess the input image\n","image = Image.open('/content/drive/MyDrive/01 Who R U.png')  # Replace with the path to your input image\n","if image.mode != 'RGB':\n","    image = image.convert('RGB')\n","preprocessed_image = preprocess(image)\n","\n","# Add a batch dimension to the preprocessed image\n","preprocessed_image = preprocessed_image.unsqueeze(0)\n","\n","# Make predictions\n","with torch.no_grad():\n","    output = model(preprocessed_image)\n","    _, predicted_class = torch.max(output, 1)\n","\n","# Get the predicted genre name\n","predicted_genre = genre_names[predicted_class.item()]\n","\n","print(predicted_genre)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CIX9rhFtcLPh","executionInfo":{"status":"ok","timestamp":1689603321313,"user_tz":-330,"elapsed":1013,"user":{"displayName":"Jawahar Reddy","userId":"14346035854948102594"}},"outputId":"d84eab91-7d09-4352-bac5-d3d070fbc00b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["hiphop\n"]}]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1KMS6u17ebeqtbpke_OdMVrGNbWE6g5LM","authorship_tag":"ABX9TyMUwM2ZNd86iJh9Z6rQEND6"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}