{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python_speech_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "from python_speech_features import mfcc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the Attention Mechanism\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.W = nn.Linear(input_dim, input_dim)\n",
    "        self.V = nn.Linear(input_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        scores = self.V(torch.tanh(self.W(x)))  # Compute attention scores\n",
    "        weights = torch.nn.functional.softmax(scores, dim=1)  # Apply softmax to get attention weights\n",
    "        context_vector = torch.sum(weights * x, dim=1)  # Compute context vector\n",
    "        return context_vector\n",
    "\n",
    "# Define the CRNN model with Attention Mechanism\n",
    "class CRNNWithAttention(nn.Module):\n",
    "    def __init__(self, input_size, num_filters, rnn_hidden_size, output_size):\n",
    "        super(CRNNWithAttention, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=num_filters, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=num_filters, out_channels=num_filters*2, kernel_size=3, stride=2, padding=1)\n",
    "        self.rnn = nn.LSTM(input_size=num_filters*2, hidden_size=rnn_hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.attention = Attention(input_dim=rnn_hidden_size*2)  # Add attention layer\n",
    "        self.fc = nn.Linear(rnn_hidden_size*2, output_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # Change shape to (batch, seq_len, features)\n",
    "        x = self.conv1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "\n",
    "        x = x.permute(0, 2, 1)  # Change shape to (batch, seq_len, input_size)\n",
    "        x, _ = self.rnn(x)\n",
    "        \n",
    "        # Apply attention mechanism\n",
    "        x = self.attention(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Load the audio dataset\n",
    "def loadDataset(directory, max_folders):\n",
    "    dataset = []\n",
    "    i = 0\n",
    "    for folder in os.listdir(directory):\n",
    "        i += 1\n",
    "        if i > max_folders:\n",
    "            break\n",
    "        for file in os.listdir(os.path.join(directory, folder)):\n",
    "            file_path = os.path.join(directory, folder, file)\n",
    "            if file == \".DS_Store\" or os.path.isdir(file_path):\n",
    "                continue\n",
    "            try:\n",
    "                (rate, sig) = wav.read(file_path)\n",
    "                mfcc_feat = mfcc(sig, rate, winlen=0.020, appendEnergy=False)\n",
    "                feature = (mfcc_feat, folder)\n",
    "                dataset.append(feature)\n",
    "            except ValueError as e:\n",
    "                print(f\"Skipping file '{file_path}': {str(e)}\")\n",
    "    return dataset\n",
    "\n",
    "# Load the dataset\n",
    "directory = \"/content/drive/MyDrive/Deep Learning/genres_original\"\n",
    "dataset = loadDataset(directory, max_folders=100)\n",
    "\n",
    "# Find the maximum length of the features\n",
    "max_length = max(len(data[0]) for data in dataset)\n",
    "\n",
    "# Pad or truncate sequences to the maximum length\n",
    "def pad_or_truncate(feature, max_length):\n",
    "    length = feature.shape[0]\n",
    "    if length > max_length:\n",
    "        return feature[:max_length]\n",
    "    elif length < max_length:\n",
    "        padded_feature = np.zeros((max_length, feature.shape[1]))\n",
    "        padded_feature[:length] = feature\n",
    "        return padded_feature\n",
    "    return feature\n",
    "\n",
    "# Process features\n",
    "X = np.array([pad_or_truncate(data[0], max_length) for data in dataset])\n",
    "y = np.array([data[1] for data in dataset])\n",
    "\n",
    "# Normalize the input features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = np.array([scaler.fit_transform(x) for x in X])\n",
    "\n",
    "# Convert labels to integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y_encoded, dtype=torch.long).to(device)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.33, random_state=1)\n",
    "\n",
    "# Create DataLoader for batch processing, utilizing more workers for faster data loading\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Define the neural network hyperparameters with simplified architecture\n",
    "input_size = X_scaled[0].shape[1]  # Number of features (13 for MFCC)\n",
    "num_filters = 32  # Reduced filters for faster training\n",
    "rnn_hidden_size = 64  # Reduced hidden size\n",
    "output_size = len(np.unique(y_encoded))\n",
    "\n",
    "# Create the CRNN model with attention\n",
    "model = CRNNWithAttention(input_size, num_filters, rnn_hidden_size, output_size).to(device)\n",
    "\n",
    "# Define the loss function and optimizer with L2 regularization\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)  # Increased learning rate for faster convergence\n",
    "\n",
    "# Early stopping and learning rate scheduler\n",
    "early_stopping_patience = 10\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5, verbose=True)\n",
    "\n",
    "# Gradient clipping to avoid exploding gradients\n",
    "max_norm = 5.0\n",
    "\n",
    "# Train the CRNN model with early stopping\n",
    "num_epochs = 50  # Reduced epochs\n",
    "best_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print average loss for the epoch\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Scheduler step\n",
    "    scheduler.step(avg_loss)\n",
    "\n",
    "    # Early stopping condition\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        patience_counter = 0\n",
    "        # Save model checkpoint\n",
    "        torch.save(model.state_dict(), \"/content/drive/MyDrive/Deep Learning/crnn_model_best.pth\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= early_stopping_patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "# Evaluate the CRNN model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Save the label_encoder\n",
    "label_encoder_save_path = \"/content/drive/MyDrive/Deep Learning/label_encoder.pkl\"\n",
    "joblib.dump(label_encoder, label_encoder_save_path)\n",
    "print(f\"Label encoder saved to {label_encoder_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "from python_speech_features import mfcc\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import joblib\n",
    "\n",
    "# Save the label_encoder\n",
    "label_encoder_save_path = \"/content/drive/MyDrive/Deep Learning/label_encoder.pkl\"\n",
    "joblib.dump(label_encoder, label_encoder_save_path)\n",
    "print(f\"Label encoder saved to {label_encoder_save_path}\")\n",
    "\n",
    "# Define the Attention Mechanism\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.W = nn.Linear(hidden_size, hidden_size)\n",
    "        self.v = nn.Linear(hidden_size, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, hidden_size)\n",
    "        scores = self.v(torch.tanh(self.W(x)))  # (batch_size, seq_len, 1)\n",
    "        weights = torch.nn.functional.softmax(scores, dim=1)  # (batch_size, seq_len, 1)\n",
    "        context = torch.sum(weights * x, dim=1)  # (batch_size, hidden_size)\n",
    "        return context\n",
    "\n",
    "# Define the CRNN model with Attention Mechanism\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self, input_size, num_filters, rnn_hidden_size, output_size):\n",
    "        super(CRNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=num_filters, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=num_filters, out_channels=num_filters*2, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        self.rnn = nn.LSTM(input_size=num_filters*2, hidden_size=rnn_hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.attention = Attention(hidden_size=rnn_hidden_size*2)\n",
    "        self.fc = nn.Linear(rnn_hidden_size*2, output_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # Change shape to (batch, seq_len, features)\n",
    "        x = self.conv1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = x.permute(0, 2, 1)  # Change shape to (batch, seq_len, input_size)\n",
    "        x, _ = self.rnn(x)\n",
    "        x = self.attention(x)  # Apply attention mechanism\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Load the CRNN model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_size = 13  # Number of MFCC features\n",
    "num_filters = 32\n",
    "rnn_hidden_size = 64\n",
    "output_size = len(label_encoder.classes_)  # Number of classes\n",
    "model = CRNN(input_size, num_filters, rnn_hidden_size, output_size).to(device)\n",
    "\n",
    "model_load_path = \"/content/drive/MyDrive/Deep Learning/crnn_model.pth\"\n",
    "model.load_state_dict(torch.load(model_load_path))\n",
    "model.eval()\n",
    "\n",
    "# Define preprocessing and transformation functions\n",
    "def preprocess_audio(file_path, max_length=1000):\n",
    "    rate, sig = wav.read(file_path)\n",
    "    mfcc_feat = mfcc(sig, rate, winlen=0.020, appendEnergy=False)\n",
    "    padded_mfcc = pad_or_truncate(mfcc_feat, max_length)\n",
    "    return padded_mfcc\n",
    "\n",
    "def pad_or_truncate(feature, max_length):\n",
    "    length = feature.shape[0]\n",
    "    if length > max_length:\n",
    "        return feature[:max_length]\n",
    "    elif length < max_length:\n",
    "        padded_feature = np.zeros((max_length, feature.shape[1]))\n",
    "        padded_feature[:length] = feature\n",
    "        return padded_feature\n",
    "    return feature\n",
    "\n",
    "# Load and preprocess the audio file\n",
    "audio_path = \"/content/drive/MyDrive/Deep Learning/genres_original/pop/pop.00047.wav\"\n",
    "mfcc_features = preprocess_audio(audio_path)\n",
    "mfcc_features = StandardScaler().fit_transform(mfcc_features)  # Normalize\n",
    "mfcc_features_tensor = torch.tensor(mfcc_features, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "# Make a prediction\n",
    "with torch.no_grad():\n",
    "    output = model(mfcc_features_tensor)\n",
    "    _, predicted_class = torch.max(output, 1)\n",
    "\n",
    "# Map prediction to label\n",
    "predicted_label = label_encoder.inverse_transform([predicted_class.item()])[0]\n",
    "print(f\"Predicted label: {predicted_label}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
